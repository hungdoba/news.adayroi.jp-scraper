# News Scraper for hungba.net

A Python-based news scraping and processing pipeline that fetches articles from some news resource in the internet, groups them, translates content, and deploys to a Next.js website.

## Features

- ğŸ” **News Scraping**: Fetches articles from various news sources on the internet
- ğŸ¤– **AI Grouping**: Groups related articles using Gemini AI
- ğŸ“ **Content Processing**: Converts HTML to Markdown format
- ğŸŒ **Translation**: Translates articles using AI
- ğŸ–¼ï¸ **Image Processing**: Downloads and processes article images
- ğŸš€ **Auto Deployment**: Deploys to Next.js website

## Project Structure

```
news.hungba.net-scraper/
â”œâ”€â”€ run.py                      # Main launcher script (run this!)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # Main application logic
â”‚   â”œâ”€â”€ pipeline.py             # Pipeline orchestrator
â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”œâ”€â”€ logging_config.py       # Logging setup
â”‚   â”œâ”€â”€ exceptions.py           # Custom exceptions
â”‚   â”œâ”€â”€ core/                   # Core business logic
â”‚   â”‚   â”œâ”€â”€ scraper.py         # Web scraping functionality
â”‚   â”‚   â”œâ”€â”€ gemini.py          # AI processing (grouping, translation)
â”‚   â”‚   â”œâ”€â”€ image.py           # Image processing utilities
â”‚   â”‚   â””â”€â”€ deploy.py          # Deployment logic
â”‚   â”œâ”€â”€ models/                 # Data models
â”‚   â”‚   â””â”€â”€ new_feed.py        # NewsFeed data model
â”‚   â””â”€â”€ utils/                  # Utility functions
â”‚       â”œâ”€â”€ file.py            # File operations
â”‚       â”œâ”€â”€ html.py            # HTML processing
â”‚       â”œâ”€â”€ log.py             # Logging utilities
â”‚       â””â”€â”€ execute.py         # Command execution
â”œâ”€â”€ data/                       # Data processing pipeline folders
â”‚   â”œâ”€â”€ 1.raw_html/            # Raw scraped HTML
â”‚   â”œâ”€â”€ 2.groups/              # Grouped articles JSON
â”‚   â”œâ”€â”€ 3.merged/              # Merged HTML files
â”‚   â”œâ”€â”€ 4.markdown/            # Converted markdown
â”‚   â”œâ”€â”€ 5.translated/          # Translated content
â”‚   â””â”€â”€ 6.images/              # Downloaded images
â”œâ”€â”€ logs/                       # Application logs
â”œâ”€â”€ .env                        # Environment variables (create from .env.example)
â”œâ”€â”€ .env.example                # Environment variables template
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ processed_ids.txt          # Processed article IDs log
â””â”€â”€ README.md                  # This file
```

## Installation

1. **Clone the repository**:

   ```bash
   git clone <repository-url>
   cd news.hungba.net-scraper
   ```

2. **Create virtual environment**:

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**:
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

## Configuration

Key environment variables in `.env`:

- `FEED_URL`: News search URL
- `NEWS_FEED_SELECTOR`: CSS selector for news items
- `GOOGLE_API_KEY`: Google Gemini API key
- `NEXTJS_DIR`: Path to Next.js deployment directory
- `OBSIDIAN_PATH`: Path to Obsidian executable

## Usage

### Run Complete Pipeline

By default, the pipeline **skips opening Obsidian** for automated workflows:

```bash
python run.py
```

### Run Pipeline With Obsidian

If you want to review content in Obsidian before deployment:

```bash
python run.py --use-obsidian
```

### Run Individual Steps

```bash
# Run specific pipeline steps
python run.py --step scrape      # Scrape news feed
python run.py --step group       # Group articles with AI
python run.py --step merge       # Merge related articles
python run.py --step convert     # Convert to Markdown
python run.py --step translate   # Translate content
python run.py --step images      # Download images
python run.py --step clean       # Clean data directories
```

### View Help

```bash
python run.py --help
```

### Set Log Level

```bash
python run.py --log-level DEBUG
```

## Pipeline Steps

1. **Scrape News Feed**: Fetches new articles from News
2. **Group Articles**: Uses AI to group related articles
3. **Merge Articles**: Combines related articles into single files
4. **Convert to Markdown**: Converts HTML to Markdown format
5. **Translate Content**: Translates articles to target language
6. **Download Images**: Fetches and processes article images
7. **Open Obsidian**: Opens content in Obsidian for review
8. **Copy to Next.js**: Moves content to Next.js project
9. **Deploy**: Builds and deploys the website

## Dependencies

- `beautifulsoup4`: HTML parsing
- `markitdown`: HTML to Markdown conversion
- `requests`: HTTP requests
- `python-dotenv`: Environment variable management
- `google-genai`: Google Gemini API for AI processing
- `Pillow`: Image processing

## License

MIT License

## Support

For issues and questions, please open an issue on GitHub.
